{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df9b3ac-e01a-40f0-ae03-295f4e485dc4",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Dieses Notebook dient der Extraktion und Aufbereitung von Daten aus dem TIGER-Korpus zur weiteren Verarbeitung. Die zugrunde liegende Datenvorbereitung orientiert sich an diesem https://github.com/theodm/gender-assistenz/blob/master/results/tiger_extract.py, wurde jedoch in mehreren Punkten überarbeitet und verbessert. Die Artikel werden automatisch segmentiert und einer eindeutigen Artikel-ID zugewiesen. Zudem erfolgt eine automatische Filterung der Autorinnen und Autoren, sodass dieser Schritt nicht mehr manuell durchgeführt werden muss.\n",
    "## Datenauslesen\n",
    "Im ersten Schritt werden die Daten aus der XML-Datei extrahiert. Dabei sollen Wörter, die als grammatisch männlich erkannt werden, durch zwei Bindestriche vor und nach dem Wort markiert werden. Die Texte werden artikelweise in eine Ausgabedatei geschrieben, um anschließend manuell weiterbearbeitet werden zu können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3764fde6-c6f0-4805-8de4-49e5f16871ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import textdescriptives as td\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaef78d-0e9b-4e5c-ac8a-6bc11e3c94ee",
   "metadata": {},
   "source": [
    "Zunächst wird die Datei eingelesen, die eine Zuordnung der einzelnen Sätze zu ihren jeweiligen Artikeln enthält. Die Informationen werden in einem Dictionary gespeichert, um eine strukturierte Weiterverarbeitung zu ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8830953e-dddd-487b-9f75-72840f257e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_documents_dict = {}\n",
    "sentences_to_type_dict = {}\n",
    "with open(\"sentences.tsv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")  \n",
    "    for row in reader:\n",
    "        if len(row) >= 3:  # Sicherstellen, dass die Zeile mindestens drei Spalten hat\n",
    "            sentence_id = row[1]  # ID als Schlüssel (Spalte B)\n",
    "            article_id = row[0]  # Erste Spalte als Wert (Spalte A)\n",
    "            _type = row[2]\n",
    "            sentences_to_documents_dict[sentence_id] = article_id\n",
    "            sentences_to_type_dict[sentence_id] = _type\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71a30f-f1e5-426f-9a6b-96ac9f2cfa83",
   "metadata": {},
   "source": [
    "Anschließend wird die TIGER-XML-Datei eingelesen. Damit dieser Schritt erfolgreich ausgeführt werden kann, muss die Datei unter dem erwarteten Pfad verfügbar sein. Die enthaltenen Sätze werden dabei den zuvor zugeordneten Artikeln entsprechend sortiert abgespeichert. Potenziell generische Maskulina werden im Text durch die Markierung mit zwei Bindestrichen vor und nach dem betreffenden Wort kenntlich gemacht (z. B. --Lehrer--)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d252bd1a-1c8c-48e9-b0f0-b03babf2e441",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tiger_release_aug07.corrected.16012013.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreparedData.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outputFile:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event, s_tag \u001b[38;5;129;01min\u001b[39;00m \u001b[43mET\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtiger_release_aug07.corrected.16012013.xml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m         tag_id\u001b[38;5;241m=\u001b[39ms_tag\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m      7\u001b[0m         current_article \u001b[38;5;241m=\u001b[39m sentences_to_documents_dict[tag_id]\n",
      "File \u001b[0;32msrc/lxml/iterparse.pxi:77\u001b[0m, in \u001b[0;36mlxml.etree.iterparse.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tiger_release_aug07.corrected.16012013.xml'"
     ]
    }
   ],
   "source": [
    "# Das ist die ID des ersten Artikels diese kann hier ausgelesen werden\n",
    "previous_article = sentences_to_documents_dict[\"1\"]\n",
    "counter = 0\n",
    "with open(\"preparedData.txt\", \"w\", encoding=\"utf-8\") as outputFile:\n",
    "    for event, s_tag in ET.iterparse(\"tiger_release_aug07.corrected.16012013.xml\", events=(\"end\",), tag=f\"s\"):\n",
    "        tag_id=s_tag.get(\"id\")[1:]\n",
    "        current_article = sentences_to_documents_dict[tag_id]\n",
    "        if current_article != previous_article:\n",
    "            outputFile.write(f\"\\n---\\n\\nArtikelId: {current_article}\\n\") \n",
    "            previous_article = current_article\n",
    "        # Hinter diesem type versteckt sich der \n",
    "        if sentences_to_type_dict[tag_id] == \"Meta\":\n",
    "            continue\n",
    "        graph_tag = s_tag.find(f\"graph\")\n",
    "        terminals_tag = graph_tag.find(f\"terminals\")\n",
    "        t_tags = terminals_tag.findall(f\"t\")\n",
    "\n",
    "        sentence = []\n",
    "        for t_tag in t_tags:\n",
    "            word = {}\n",
    "    \n",
    "            word[\"word\"] = t_tag.attrib[\"word\"]\n",
    "            word[\"pos\"] = t_tag.attrib[\"pos\"]\n",
    "            word[\"number\"] = t_tag.attrib[\"number\"]\n",
    "            word[\"gender\"] = t_tag.attrib[\"gender\"]\n",
    "            word[\"case\"] = t_tag.attrib[\"case\"]\n",
    "    \n",
    "            if (word[\"gender\"] in [\"Masc\", \"*\"] or (word[\"gender\"] in [\"Neut\"] and word[\"number\"] == \"Plur\")) and word[\"pos\"] in [\"PDS\", \"PIS\", \"PPER\", \"PPOSS\", \"PRELS\", \"PWS\", \"NN\"]:\n",
    "                word[\"word\"] = \"--\" + word[\"word\"] + \"--\"\n",
    "    \n",
    "            sentence.append(word)\n",
    "    \n",
    "        outputFile.write(\" \".join(x[\"word\"] for x in sentence).replace(\" ,\", \",\").replace(\" ;\", \";\").replace(\" .\", \".\").replace(\" :\", \":\").replace(\" ?\", \"?\").replace(\" .\", \".\").replace(\" !\", \"!\").replace(\"`` \", \"\\\"\").replace(\" `` \", \"\\\"\").replace(\" ``\", \"\\\"\").replace(\"'' \", \"\\\"\").replace(\" '' \", \"\\\"\").replace(\" ''\", \"\\\"\").replace(\"( \", \"(\").replace(\" )\", \")\") + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391cb346-5e49-4bc3-9722-05c4f7de0f99",
   "metadata": {},
   "source": [
    "n der zuvor erstellten Datei erfolgt im nächsten Schritt eine manuelle Annotation. Dabei wird für jede markierte Wortform entschieden, ob es sich um ein generisches Maskulinum handelt und somit eine geschlechtergerechte Korrektur erforderlich ist. Als generisches Maskulinum gilt ein Ausdruck, wenn eine maskuline Form verwendet wird, um eine gemischtgeschlechtliche oder geschlechtsunspezifische Gruppe zu bezeichnen, ohne dass eine explizite geschlechtliche Markierung vorliegt. Typische Beispiele sind maskuline Substantive wie Student, Arzt oder Bürger, die in einem allgemeinen Sinn für alle Geschlechter stehen. Ausschlaggebend ist dabei der Gebrauchskontext: Liegt keine eindeutig geschlechtsspezifische Referenz vor und fungiert die maskuline Form als Standard, ist eine Korrektur in der Regel angezeigt. Die annotierten Formen werden entsprechend gekennzeichnet: Korrekturbedürftige Begriffe erhalten ein vorangestelltes Ausrufezeichen („!\"), nicht korrekturbedürftige Formen ein umgekehrtes Schrägzeichen („\\“).\n",
    "## Weiterverarbeitung der manuellen Daten\n",
    "Im folgenden Abschnitt werden die manuell annotierten Daten in ein DataFrame überführt. Dabei wird der ursprüngliche Fließtext ohne Markierungen rekonstruiert, um eine neutrale Vergleichsbasis zu gewährleisten. Zusätzlich erfolgt eine Segmentierung der Texte auf Satzebene: Die einzelnen Sätze jedes Artikels werden extrahiert und in Form einer separaten Liste gespeichert. Diese Struktur ermöglicht eine feingranulare Analyse sowie eine spätere Zuordnung von Annotationen und Systemergebnissen auf Satzebene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4543621-c3ad-47a7-857f-5f0f06a36fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preparedData_manual.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Aufteilen in Blöcke anhand des Trennzeichen\n",
    "artikel_blocks = content.strip().split('\\n\\n---\\n\\n')\n",
    "\n",
    "data = []\n",
    "\n",
    "for block in artikel_blocks:\n",
    "    lines = block.strip().split('\\n')\n",
    "    artikel_id = lines[0]\n",
    "    text = '\\n'.join(lines[1:])  # Falls der Artikeltext mehrzeilig ist\n",
    "    data.append((artikel_id, text))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ArtikelId', 'Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eca28e-d250-480b-8a25-ff57acbcea48",
   "metadata": {},
   "source": [
    "Der unmarkierte Volltext und satzweise Listen (markiert/unmarkiert) werden aus den manuell annotierten Daten generiert. Eine Prüfung stellt sicher, dass keine unmarkierten generisch-maskulinen Formen im Text verbleiben, bei Verstößen wird ein Fehler ausgelöst, um manuelle Nachkorrektur zu erzwingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1bf3db-23dd-4248-981d-ba2419f6b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_check_article(article):\n",
    "    #\n",
    "    # Parst einen Artikel im\n",
    "    #\n",
    "    t = article\n",
    "    ci = 0\n",
    "    clean_article = \"\"\n",
    "\n",
    "\n",
    "    number_of_ignored_chars = 0\n",
    "    try:\n",
    "        while ci < len(article)-2:\n",
    "            if article[ci] in (\"!\", \"\\\\\") and article[ci+1:ci+3] == \"--\":\n",
    "                # Zum Anfang des Wortes springen\n",
    "                ci = ci + 3\n",
    "                while True:\n",
    "                    if article[ci:ci+2] == \"--\":\n",
    "                        ci = ci + 2\n",
    "                        break\n",
    "                    clean_article = clean_article + article[ci]\n",
    "                    ci = ci + 1\n",
    "                continue\n",
    "    \n",
    "            if t[ci] == \"-\" and t[ci + 1] == \"-\":\n",
    "                raise Exception(\"-- found: \" + article[ci-10:ci+20])\n",
    "    \n",
    "            clean_article = clean_article + article[ci]\n",
    "            ci = ci + 1\n",
    "    \n",
    "        return clean_article\n",
    "    except: \n",
    "        print(article)\n",
    "        raise Exception(\"-- found: \" + article[ci-10:ci+20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b1c24e-99f4-4db2-9c2f-a01fc594d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_unmarked'] = df['Text'].apply(clean_and_check_article)\n",
    "df['Sentences_marked'] = df['Text'].apply(lambda x: x.split('\\n'))\n",
    "df['Sentences_unmarked'] = df['Text_unmarked'].apply(lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d2d7b-0961-4754-9e8d-5e3ac9263444",
   "metadata": {},
   "source": [
    "Um später detaillierte Analysen zu ermöglichen werden an dieser Stelle noch die dependency distance und die prop_adjacent distance berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a5afa72-b9b9-4fae-b863-fdba15505f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spacy310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/spacy310/lib/python3.10/site-packages/IPython/core/formatters.py:406: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  return method()\n",
      "/opt/anaconda3/envs/spacy310/lib/python3.10/site-packages/IPython/core/formatters.py:406: FutureWarning: RangeIndex.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  return method()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtikelId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_unmarked</th>\n",
       "      <th>Sentences_marked</th>\n",
       "      <th>Sentences_unmarked</th>\n",
       "      <th>dependency_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtikelId: 0001_0001</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger \\--...</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger Dik...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger \\-...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger Di...</td>\n",
       "      <td>{'dependency_distance_mean': 2.965713889246949...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtikelId: 0001_0002</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>{'dependency_distance_mean': 2.782908048111762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtikelId: 0001_0003</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>{'dependency_distance_mean': 3.174690061989753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArtikelId: 0001_0004</td>\n",
       "      <td>Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...</td>\n",
       "      <td>Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...</td>\n",
       "      <td>[Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...</td>\n",
       "      <td>[Im Blickpunkt:, Ermittlungen gegen Autonome, ...</td>\n",
       "      <td>{'dependency_distance_mean': 3.137275306681283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ArtikelId: 0001_0005</td>\n",
       "      <td>Für ehrliche !--Kunden-- ist es ein \\--Schock-...</td>\n",
       "      <td>Für ehrliche Kunden ist es ein Schock\\nZahl de...</td>\n",
       "      <td>[Für ehrliche !--Kunden-- ist es ein \\--Schock...</td>\n",
       "      <td>[Für ehrliche Kunden ist es ein Schock, Zahl d...</td>\n",
       "      <td>{'dependency_distance_mean': 2.704419452574911...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ArtikelId                                               Text   \n",
       "0  ArtikelId: 0001_0001  \"Ross Perot wäre vielleicht ein prächtiger \\--...  \\\n",
       "1  ArtikelId: 0001_0002  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  ArtikelId: 0001_0003  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  ArtikelId: 0001_0004  Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...   \n",
       "4  ArtikelId: 0001_0005  Für ehrliche !--Kunden-- ist es ein \\--Schock-...   \n",
       "\n",
       "                                       Text_unmarked   \n",
       "0  \"Ross Perot wäre vielleicht ein prächtiger Dik...  \\\n",
       "1  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...   \n",
       "4  Für ehrliche Kunden ist es ein Schock\\nZahl de...   \n",
       "\n",
       "                                    Sentences_marked   \n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger \\-...  \\\n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...   \n",
       "4  [Für ehrliche !--Kunden-- ist es ein \\--Schock...   \n",
       "\n",
       "                                  Sentences_unmarked   \n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger Di...  \\\n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im Blickpunkt:, Ermittlungen gegen Autonome, ...   \n",
       "4  [Für ehrliche Kunden ist es ein Schock, Zahl d...   \n",
       "\n",
       "                                 dependency_distance  \n",
       "0  {'dependency_distance_mean': 2.965713889246949...  \n",
       "1  {'dependency_distance_mean': 2.782908048111762...  \n",
       "2  {'dependency_distance_mean': 3.174690061989753...  \n",
       "3  {'dependency_distance_mean': 3.137275306681283...  \n",
       "4  {'dependency_distance_mean': 2.704419452574911...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "nlp.add_pipe(\"textdescriptives/dependency_distance\")  # fügt alle Features hinzu\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        \"dependency_distance\": doc._.dependency_distance,\n",
    "    }\n",
    "\n",
    "features = df[\"Text_unmarked\"].apply(extract_features)\n",
    "\n",
    "df[\"dependency_distance\"] = features.apply(lambda x: x[\"dependency_distance\"])\n",
    "\n",
    "# Optional: df.head() zur Kontrolle\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980ec58-ed79-46ff-81de-0194288a737f",
   "metadata": {},
   "source": [
    "\n",
    "An dieser Stelle sind die Daten soweit vorbereitet um im [DataExploration](./DataExploration.ipynb) weiter untersucht zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60a9e7e-31c7-4313-8350-b046ab810be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data_prepared_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233089d7-9b2b-40a0-afc6-14cbbc382520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtikelId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_unmarked</th>\n",
       "      <th>Sentences_marked</th>\n",
       "      <th>Sentences_unmarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtikelId: 0001_0001</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger \\--...</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger Dik...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger \\-...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtikelId: 0001_0002</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtikelId: 0001_0003</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArtikelId: 0001_0004</td>\n",
       "      <td>Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...</td>\n",
       "      <td>Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...</td>\n",
       "      <td>[Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...</td>\n",
       "      <td>[Im Blickpunkt:, Ermittlungen gegen Autonome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ArtikelId: 0001_0005</td>\n",
       "      <td>Für ehrliche !--Kunden-- ist es ein \\--Schock-...</td>\n",
       "      <td>Für ehrliche Kunden ist es ein Schock\\nZahl de...</td>\n",
       "      <td>[Für ehrliche !--Kunden-- ist es ein \\--Schock...</td>\n",
       "      <td>[Für ehrliche Kunden ist es ein Schock, Zahl d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ArtikelId                                               Text  \\\n",
       "0  ArtikelId: 0001_0001  \"Ross Perot wäre vielleicht ein prächtiger \\--...   \n",
       "1  ArtikelId: 0001_0002  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  ArtikelId: 0001_0003  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  ArtikelId: 0001_0004  Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...   \n",
       "4  ArtikelId: 0001_0005  Für ehrliche !--Kunden-- ist es ein \\--Schock-...   \n",
       "\n",
       "                                       Text_unmarked  \\\n",
       "0  \"Ross Perot wäre vielleicht ein prächtiger Dik...   \n",
       "1  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...   \n",
       "4  Für ehrliche Kunden ist es ein Schock\\nZahl de...   \n",
       "\n",
       "                                    Sentences_marked  \\\n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger \\-...   \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...   \n",
       "4  [Für ehrliche !--Kunden-- ist es ein \\--Schock...   \n",
       "\n",
       "                                  Sentences_unmarked  \n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger Di...  \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...  \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...  \n",
       "3  [Im Blickpunkt:, Ermittlungen gegen Autonome, ...  \n",
       "4  [Für ehrliche Kunden ist es ein Schock, Zahl d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80d772-94f6-4b1d-946f-d7ecab893042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
