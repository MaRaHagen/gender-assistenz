{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df9b3ac-e01a-40f0-ae03-295f4e485dc4",
   "metadata": {},
   "source": [
    "# Datenvorbereitung\n",
    "Dieses Notebook soll dazu dienen die Daten aus dem TIGER Korpus auszulesen und für die weiteren Schritte vorzubereiten. Diese Datenvorbereritung basiert auf https://github.com/theodm/gender-assistenz/blob/master/results/tiger_extract.py wird allerdings an gewissen Punkten verbessert. Die Artikel werden bereits automatisch getrennt und ihrer Artikel-ID zugeordnet und die Autoren/Autorinnen der Artikel werden gefiltert, dies muss also nicht mehr manuell passieren.\n",
    "## Datenauslesen\n",
    "Zunächst müssen die Daten aus der XML ausgelesen werden, dabei sollen die als Männlich erkannten Wörter mit zwei Bindestrichen vor und nach dem Wort markiert werden. Die Daten sollen Artikelweise in eine Output Datei gelegt werden um dort manuell weiter bearbeitet zu werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3764fde6-c6f0-4805-8de4-49e5f16871ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import textdescriptives as td\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaef78d-0e9b-4e5c-ac8a-6bc11e3c94ee",
   "metadata": {},
   "source": [
    "Zunächst wird die Datei, welche die Sätze ihren Artikeln zurodnet ausgelesen und in einem dictionary gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8830953e-dddd-487b-9f75-72840f257e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_documents_dict = {}\n",
    "sentences_to_type_dict = {}\n",
    "with open(\"sentences.tsv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")  \n",
    "    for row in reader:\n",
    "        if len(row) >= 3:  # Sicherstellen, dass die Zeile mindestens drei Spalten hat\n",
    "            sentence_id = row[1]  # ID als Schlüssel (Spalte B)\n",
    "            article_id = row[0]  # Erste Spalte als Wert (Spalte A)\n",
    "            _type = row[2]\n",
    "            sentences_to_documents_dict[sentence_id] = article_id\n",
    "            sentences_to_type_dict[sentence_id] = _type\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71a30f-f1e5-426f-9a6b-96ac9f2cfa83",
   "metadata": {},
   "source": [
    "Daraufhin wird die Output Datei eingelesen und in Artikel sortiert abgespeichert. Hierbei werden die potentiell generischen Maskulina mit zwei \"--\" vor und hinter dem Wort markiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d252bd1a-1c8c-48e9-b0f0-b03babf2e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ist die ID des ersten Artikels diese kann hier ausgelesen werden\n",
    "previous_article = sentences_to_documents_dict[\"1\"]\n",
    "counter = 0\n",
    "with open(\"preparedData.txt\", \"w\", encoding=\"utf-8\") as outputFile:\n",
    "    for event, s_tag in ET.iterparse(\"tiger_release_aug07.corrected.16012013.xml\", events=(\"end\",), tag=f\"s\"):\n",
    "        tag_id=s_tag.get(\"id\")[1:]\n",
    "        current_article = sentences_to_documents_dict[tag_id]\n",
    "        if current_article != previous_article:\n",
    "            outputFile.write(f\"\\n---\\n\\nArtikelId: {current_article}\\n\") \n",
    "            previous_article = current_article\n",
    "        # Hinter diesem type versteckt sich der \n",
    "        if sentences_to_type_dict[tag_id] == \"Meta\":\n",
    "            continue\n",
    "        graph_tag = s_tag.find(f\"graph\")\n",
    "        terminals_tag = graph_tag.find(f\"terminals\")\n",
    "        t_tags = terminals_tag.findall(f\"t\")\n",
    "\n",
    "        sentence = []\n",
    "        for t_tag in t_tags:\n",
    "            word = {}\n",
    "    \n",
    "            word[\"word\"] = t_tag.attrib[\"word\"]\n",
    "            word[\"pos\"] = t_tag.attrib[\"pos\"]\n",
    "            word[\"number\"] = t_tag.attrib[\"number\"]\n",
    "            word[\"gender\"] = t_tag.attrib[\"gender\"]\n",
    "            word[\"case\"] = t_tag.attrib[\"case\"]\n",
    "    \n",
    "            if (word[\"gender\"] in [\"Masc\", \"*\"] or (word[\"gender\"] in [\"Neut\"] and word[\"number\"] == \"Plur\")) and word[\"pos\"] in [\"PDS\", \"PIS\", \"PPER\", \"PPOSS\", \"PRELS\", \"PWS\", \"NN\"]:\n",
    "                word[\"word\"] = \"--\" + word[\"word\"] + \"--\"\n",
    "    \n",
    "            sentence.append(word)\n",
    "    \n",
    "        outputFile.write(\" \".join(x[\"word\"] for x in sentence).replace(\" ,\", \",\").replace(\" ;\", \";\").replace(\" .\", \".\").replace(\" :\", \":\").replace(\" ?\", \"?\").replace(\" .\", \".\").replace(\" !\", \"!\").replace(\"`` \", \"\\\"\").replace(\" `` \", \"\\\"\").replace(\" ``\", \"\\\"\").replace(\"'' \", \"\\\"\").replace(\" '' \", \"\\\"\").replace(\" ''\", \"\\\"\").replace(\"( \", \"(\").replace(\" )\", \")\") + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391cb346-5e49-4bc3-9722-05c4f7de0f99",
   "metadata": {},
   "source": [
    "In der soeben erstellten Datei muss nun manuell für die ob es sich um ein generisches Maskulinum handelt und somit korrekturbedürftig ist oder nicht. Ein Ausdruck gilt als generisches Maskulinum, wenn eine maskuline Wortform verwendet wird, um eine gemischtgeschlechtliche oder geschlechtsunspezifische Gruppe zu bezeichnen, ohne eine explizite geschlechtliche Markierung zu enthalten. Typischerweise betrifft dies maskuline Substantive wie Student, Arzt oder Bürger, die in einem allgemeinen Sinne für alle Geschlechter stehen sollen. Entscheidend ist der kontextuelle Gebrauch, bei dem keine eindeutige geschlechtsspezifische Zuordnung erkennbar ist und das Maskulinum als Standard-Form fungiert. Die Korrekturbedürftigen Formen werden hierbei mit einem \"!\" die nicht korrektur bedürftigen mit einem \"\\\" geprefixed. Für die ersten x Artikel werden die bereits in https://github.com/theodm/gender-assistenz/blob/master/results/demofile3.txt bestehenden manuellen Annotationen übernommen.\n",
    "## Weiterverarbeitung der manuellen Daten\n",
    "In diesem Abschnitt werden die manuell vorbereiteten Daten in ein Dataframe eingelesen dabei werden sie um den unmarkierten Text ergänzt und die einzelnen Sätze der Texte werden in eine eigene Liste gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4543621-c3ad-47a7-857f-5f0f06a36fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preparedData_manual.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Aufteilen in Blöcke anhand des Trennzeichen\n",
    "artikel_blocks = content.strip().split('\\n\\n---\\n\\n')\n",
    "\n",
    "data = []\n",
    "\n",
    "for block in artikel_blocks:\n",
    "    lines = block.strip().split('\\n')\n",
    "    artikel_id = lines[0]\n",
    "    text = '\\n'.join(lines[1:])  # Falls der Artikeltext mehrzeilig ist\n",
    "    data.append((artikel_id, text))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ArtikelId', 'Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eca28e-d250-480b-8a25-ff57acbcea48",
   "metadata": {},
   "source": [
    "Weitere Datenfelder zu dem Text ergänzen. Den ganzen Text unmarkiert und sowohl Einzelne Sätze als Liste sowohl markiert als auch unmarkiert. Diese Funktion soll einen Fehler werfen wenn unmarkierte vorkommen gefunden werden um manuell in der Datei korrigieren zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1bf3db-23dd-4248-981d-ba2419f6b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_check_article(article):\n",
    "    #\n",
    "    # Parst einen Artikel im\n",
    "    #\n",
    "    t = article\n",
    "    ci = 0\n",
    "    clean_article = \"\"\n",
    "\n",
    "\n",
    "    number_of_ignored_chars = 0\n",
    "    try:\n",
    "        while ci < len(article)-2:\n",
    "            if article[ci] in (\"!\", \"\\\\\") and article[ci+1:ci+3] == \"--\":\n",
    "                # Zum Anfang des Wortes springen\n",
    "                ci = ci + 3\n",
    "                while True:\n",
    "                    if article[ci:ci+2] == \"--\":\n",
    "                        ci = ci + 2\n",
    "                        break\n",
    "                    clean_article = clean_article + article[ci]\n",
    "                    ci = ci + 1\n",
    "                continue\n",
    "    \n",
    "            if t[ci] == \"-\" and t[ci + 1] == \"-\":\n",
    "                raise Exception(\"-- found: \" + article[ci-10:ci+20])\n",
    "    \n",
    "            clean_article = clean_article + article[ci]\n",
    "            ci = ci + 1\n",
    "    \n",
    "        return clean_article\n",
    "    except: \n",
    "        print(article)\n",
    "        raise Exception(\"-- found: \" + article[ci-10:ci+20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b1c24e-99f4-4db2-9c2f-a01fc594d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_unmarked'] = df['Text'].apply(clean_and_check_article)\n",
    "df['Sentences_marked'] = df['Text'].apply(lambda x: x.split('\\n'))\n",
    "df['Sentences_unmarked'] = df['Text_unmarked'].apply(lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8d2d7b-0961-4754-9e8d-5e3ac9263444",
   "metadata": {},
   "source": [
    "Um später detaillierte Analysen zu ermöglichen werden an dieser Stelle noch Metriken ergänzt um den schreibstil und die komplexität der Artikel besser zu beschreiben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5afa72-b9b9-4fae-b863-fdba15505f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spacy310/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'de_core_news_md' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.8.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtikelId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_unmarked</th>\n",
       "      <th>Sentences_marked</th>\n",
       "      <th>Sentences_unmarked</th>\n",
       "      <th>dependency_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtikelId: 0001_0001</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger \\--...</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger Dik...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger \\-...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger Di...</td>\n",
       "      <td>{'dependency_distance_mean': 2.858281125203935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtikelId: 0001_0002</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>{'dependency_distance_mean': 2.861873114849146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtikelId: 0001_0003</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>{'dependency_distance_mean': 3.165174122545213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArtikelId: 0001_0004</td>\n",
       "      <td>Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...</td>\n",
       "      <td>Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...</td>\n",
       "      <td>[Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...</td>\n",
       "      <td>[Im Blickpunkt:, Ermittlungen gegen Autonome, ...</td>\n",
       "      <td>{'dependency_distance_mean': 3.263254197975927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ArtikelId: 0001_0005</td>\n",
       "      <td>Für ehrliche !--Kunden-- ist es ein \\--Schock-...</td>\n",
       "      <td>Für ehrliche Kunden ist es ein Schock\\nZahl de...</td>\n",
       "      <td>[Für ehrliche !--Kunden-- ist es ein \\--Schock...</td>\n",
       "      <td>[Für ehrliche Kunden ist es ein Schock, Zahl d...</td>\n",
       "      <td>{'dependency_distance_mean': 2.742601663046218...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ArtikelId                                               Text  \\\n",
       "0  ArtikelId: 0001_0001  \"Ross Perot wäre vielleicht ein prächtiger \\--...   \n",
       "1  ArtikelId: 0001_0002  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  ArtikelId: 0001_0003  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  ArtikelId: 0001_0004  Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...   \n",
       "4  ArtikelId: 0001_0005  Für ehrliche !--Kunden-- ist es ein \\--Schock-...   \n",
       "\n",
       "                                       Text_unmarked  \\\n",
       "0  \"Ross Perot wäre vielleicht ein prächtiger Dik...   \n",
       "1  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...   \n",
       "4  Für ehrliche Kunden ist es ein Schock\\nZahl de...   \n",
       "\n",
       "                                    Sentences_marked  \\\n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger \\-...   \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...   \n",
       "4  [Für ehrliche !--Kunden-- ist es ein \\--Schock...   \n",
       "\n",
       "                                  Sentences_unmarked  \\\n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger Di...   \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im Blickpunkt:, Ermittlungen gegen Autonome, ...   \n",
       "4  [Für ehrliche Kunden ist es ein Schock, Zahl d...   \n",
       "\n",
       "                                 dependency_distance  \n",
       "0  {'dependency_distance_mean': 2.858281125203935...  \n",
       "1  {'dependency_distance_mean': 2.861873114849146...  \n",
       "2  {'dependency_distance_mean': 3.165174122545213...  \n",
       "3  {'dependency_distance_mean': 3.263254197975927...  \n",
       "4  {'dependency_distance_mean': 2.742601663046218...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "nlp.add_pipe(\"textdescriptives/dependency_distance\")  # fügt alle Features hinzu\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        \"dependency_distance\": doc._.dependency_distance,\n",
    "    }\n",
    "\n",
    "features = df[\"Text_unmarked\"].apply(extract_features)\n",
    "\n",
    "df[\"dependency_distance\"] = features.apply(lambda x: x[\"dependency_distance\"])\n",
    "\n",
    "# Optional: df.head() zur Kontrolle\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980ec58-ed79-46ff-81de-0194288a737f",
   "metadata": {},
   "source": [
    "\n",
    "An dieser Stelle sind die Daten soweit vorbereitet um im [DataExploration](./DataExploration.ipynb) weiter untersucht zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60a9e7e-31c7-4313-8350-b046ab810be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data_prepared_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233089d7-9b2b-40a0-afc6-14cbbc382520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtikelId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_unmarked</th>\n",
       "      <th>Sentences_marked</th>\n",
       "      <th>Sentences_unmarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ArtikelId: 0001_0001</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger \\--...</td>\n",
       "      <td>\"Ross Perot wäre vielleicht ein prächtiger Dik...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger \\-...</td>\n",
       "      <td>[\"Ross Perot wäre vielleicht ein prächtiger Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ArtikelId: 0001_0002</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>IBM und Siemens gelten nicht mehr als Schimpfw...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "      <td>[IBM und Siemens gelten nicht mehr als Schimpf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArtikelId: 0001_0003</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>Wechselspiel von Dramatisierung und Ignoranz\\n...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "      <td>[Wechselspiel von Dramatisierung und Ignoranz,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArtikelId: 0001_0004</td>\n",
       "      <td>Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...</td>\n",
       "      <td>Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...</td>\n",
       "      <td>[Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...</td>\n",
       "      <td>[Im Blickpunkt:, Ermittlungen gegen Autonome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ArtikelId: 0001_0005</td>\n",
       "      <td>Für ehrliche !--Kunden-- ist es ein \\--Schock-...</td>\n",
       "      <td>Für ehrliche Kunden ist es ein Schock\\nZahl de...</td>\n",
       "      <td>[Für ehrliche !--Kunden-- ist es ein \\--Schock...</td>\n",
       "      <td>[Für ehrliche Kunden ist es ein Schock, Zahl d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ArtikelId                                               Text  \\\n",
       "0  ArtikelId: 0001_0001  \"Ross Perot wäre vielleicht ein prächtiger \\--...   \n",
       "1  ArtikelId: 0001_0002  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  ArtikelId: 0001_0003  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  ArtikelId: 0001_0004  Im \\--Blickpunkt--:\\nErmittlungen gegen \\--Aut...   \n",
       "4  ArtikelId: 0001_0005  Für ehrliche !--Kunden-- ist es ein \\--Schock-...   \n",
       "\n",
       "                                       Text_unmarked  \\\n",
       "0  \"Ross Perot wäre vielleicht ein prächtiger Dik...   \n",
       "1  IBM und Siemens gelten nicht mehr als Schimpfw...   \n",
       "2  Wechselspiel von Dramatisierung und Ignoranz\\n...   \n",
       "3  Im Blickpunkt:\\nErmittlungen gegen Autonome\\nS...   \n",
       "4  Für ehrliche Kunden ist es ein Schock\\nZahl de...   \n",
       "\n",
       "                                    Sentences_marked  \\\n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger \\-...   \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...   \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...   \n",
       "3  [Im \\--Blickpunkt--:, Ermittlungen gegen \\--Au...   \n",
       "4  [Für ehrliche !--Kunden-- ist es ein \\--Schock...   \n",
       "\n",
       "                                  Sentences_unmarked  \n",
       "0  [\"Ross Perot wäre vielleicht ein prächtiger Di...  \n",
       "1  [IBM und Siemens gelten nicht mehr als Schimpf...  \n",
       "2  [Wechselspiel von Dramatisierung und Ignoranz,...  \n",
       "3  [Im Blickpunkt:, Ermittlungen gegen Autonome, ...  \n",
       "4  [Für ehrliche Kunden ist es ein Schock, Zahl d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80d772-94f6-4b1d-946f-d7ecab893042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
